---
title: "When Standard Methods Succeed"
author: "Lucy D'Agostino McGowan"
institute: "Wake Forest University"
format: kakashi-revealjs
---

## {background-color="#23373B" .center .large}

### when correlation *is* causation

```{r}
#| label: setup
#| include: false
options(
  tibble.max_extra_cols = 6, 
  tibble.width = 60
)
```

## {background-color="#23373B" .center}

### When you have no confounders and there is a linear relationship between the exposure and the outcome, that *correlation is a causal relationship*

### `r emo::ji("wow")`

## {background-color="#23373B" .center}

### When you have no confounders and there is a linear relationship between the *exposure* and the outcome, that correlation is a causal relationship

### `r emo::ji("wow")`

## {background-color="#23373B" .center}

### When you have no confounders and there is a linear relationship between the exposure and the *outcome*, that correlation is a causal relationship

### `r emo::ji("wow")`

## {background-color="#23373B" .center}

### When you have no *confounders* and there is a linear relationship between the exposure and the outcome, that correlation is a causal relationship
### `r emo::ji("wow")`

## {background-color="#23373B" .center}

### randomized controlled trials
### A/B testing

## Even in these cases, using the methods you will learn here can help! {background-color="#23373B"} 

1. Adjusting for baseline covariates can make an estimate *more efficient*
1. Propensity score weighting is *more efficient* than direct adjustment
1. Sometimes we are *more comfortable with the functional form of the propensity score* (predicting exposure) than the outcome model


## Example

* **simulated** data (100 observations)  
* Treatment is **randomly** assigned 
* There are **two baseline covariates**: `age` and `weight`

## Example

```{r}
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
library(gtsummary)
set.seed(10)
n <- 100
d <- tibble(
  age = rnorm(n, 55, 20),
  weight = rnorm(n),
  treatment = rbinom(n, 1, 0.5),
  y = treatment + 0.2 * age + 0.2 * weight + rnorm(n)
)
library(ggdag)

x <- data.frame(
  name = c("y", "trt", "age", "wt"), 
  time = c(3, 2, 1, 1)
)
dagify(
  y ~ trt + age + wt,
  coords = time_ordered_coords(x)
) |> 
  ggdag() +
  theme_dag()
```

* **True average treatment effect**: 1


## {.tiny}

:::: {.columns}

::: {.column width="33%" .fragment}
### Unadjusted model

```{r}
#| eval: false
lm(y ~ treatment, data = data)
```

```{r}
#| echo: false
#| message: false
#| warning: false
lm(y ~ treatment, d) |>
  tbl_regression() |>
  modify_column_unhide(column = std.error)
```

:::

::: {.column width="33%" .fragment}
### Adjusted model

```{r}
#| eval: false
lm(y ~ treatment + weight + age, data = data)
```

```{r}
#| echo: false
lm(y ~ treatment + weight + age, data = d) |>
  tbl_regression() |>
  modify_column_unhide(column = std.error)
```
:::

::: {.column width="33%" .fragment}
### Propensity score adjusted model

```{r}
#| echo: false
d |>
  mutate(
    p = glm(treatment ~ weight + age, data = d) |> predict(type = "response"),
    ate = treatment / p + (1 - treatment) / (1 - p)
  ) |>
  as.data.frame() -> d
library(PSW)
df <- as.data.frame(d)
x <- psw(df, 
         "treatment ~ weight + age", 
         weight = "ATE", wt = TRUE,
         out.var = "y")
tibble(
  Characteristic = "treatment",
  Beta = round(x$est.wt, 1),
  SE = round(x$std.wt, 3),
  `95% CI` = glue::glue("{round(x$est.wt - 1.96 * x$std.wt, 1)}, {round(x$est.wt + 1.96 * x$std.wt, 1)}"),
  `p-value` = "<0.001"
) |>
  knitr::kable()
```

:::
::::

## Example

* **simulated** data (10,000 observations)  
* Treatment is **randomly** assigned 
* There are **two baseline covariates**: `age` and `weight`

## {.tiny}

:::: {.columns}

::: {.column width="33%" .fragment}
### Unadjusted model

```{r}
#| eval: false
lm(y ~ treatment, data = data)
```

```{r}
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
library(gtsummary)
set.seed(10)
n <- 10000
d <- tibble(
  age = rnorm(n, 55, 20),
  weight = rnorm(n),
  treatment = rbinom(n, 1, 0.5),
  y = treatment + 0.2 * age + 0.2 * weight + rnorm(n)
)
lm(y ~ treatment, d) |>
  tbl_regression() |>
  modify_column_unhide(column = std.error)
```
:::


::: {.column width="33%" .fragment}
### Adjusted model

```{r}
#| eval: false
lm(y ~ treatment + weight + age, data = data)
```

```{r}
#| echo: false
lm(y ~ treatment + weight + age, data = d) |>
  tbl_regression() |>
  modify_column_unhide(column = std.error)
```
:::

::: {.column width="33%" .fragment}
### Propensity score adjusted model

```{r}
#| echo: false
d |>
  mutate(
    p = glm(treatment ~ weight + age, data = d) |> predict(type = "response"),
    ate = treatment / p + (1 - treatment) / (1 - p)
  ) |>
  as.data.frame() -> d
library(PSW)
df <- as.data.frame(d)
x <- psw(df, 
         "treatment ~ weight + age", 
         weight = "ATE", wt = TRUE,
         out.var = "y")
tibble(
  Characteristic = "treatment",
  Beta = round(x$est.wt, 1),
  SE = round(x$std.wt, 3),
  `95% CI` = glue::glue("{round(x$est.wt - 1.96 * x$std.wt, 1)}, {round(x$est.wt + 1.96 * x$std.wt, 1)}"),
  `p-value` = "<0.001"
) |>
  knitr::kable()
```

:::
::::

## Example

* **simulated** data (10,000 observations)  
* Treatment is **not** randomly assigned 
* There are **two baseline confounders**: `age` and `weight`
* The treatment effect is **homogeneous**

## Example

```{r}
#| echo: false
#| message: false
#| warning: false
set.seed(10)
n <- 10000
d <- tibble(
  age = rnorm(n, 55, 20),
  weight = rnorm(n),
  treatment = rbinom(n, 1, 1 / (1 + exp(-(0.01 * age + 0.1 * weight)))),
  y = treatment + 0.2 * age + 0.2 * weight + rnorm(n)
)

x <- data.frame(
  name = c("y", "trt", "age", "wt"), 
  time = c(3, 2, 1, 1)
)
dagify(
  y ~ trt + age + wt,
  trt ~ age + wt,
  coords = time_ordered_coords(x)
) |> 
  ggdag() + 
  theme_dag()
```

* **True average treatment effect**: 1

## {.tiny}

:::: {.columns}

::: {.column width="33%" .fragment}
### Unadjusted model

```{r}
#| eval: false
lm(y ~ treatment, data = data)
```

```{r}
#| echo: false
#| message: false
#| warning: false
lm(y ~ treatment, d) |>
  tbl_regression() |>
  modify_column_unhide(column = std.error)
```
:::


::: {.column width="33%" .fragment}
### Adjusted model

```{r}
#| eval: false
lm(y ~ treatment + weight + age, data = data)
```

```{r}
#| echo: false
lm(y ~ treatment + weight + age, data = d) |>
  tbl_regression() |>
  modify_column_unhide(column = std.error)
```
:::

::: {.column width="33%" .fragment}
### Propensity score adjusted model

```{r}
#| echo: false
d |>
  mutate(
    p = glm(treatment ~ weight + age, data = d) |> predict(type = "response"),
    ate = treatment / p + (1 - treatment) / (1 - p)
  ) |>
  as.data.frame() -> d
library(PSW)
df <- as.data.frame(d)
x <- psw(df, 
         "treatment ~ weight + age", 
         weight = "ATE", wt = TRUE,
         out.var = "y")
tibble(
  Characteristic = "treatment",
  Beta = round(x$est.wt, 1),
  SE = round(x$std.wt, 3),
  `95% CI` = glue::glue("{round(x$est.wt - 1.96 * x$std.wt, 1)}, {round(x$est.wt + 1.96 * x$std.wt, 1)}"),
  `p-value` = "<0.001"
) |>
  knitr::kable()
```

:::
::::

## {background-color="#23373B" .center}

### *time-varying* confounding
