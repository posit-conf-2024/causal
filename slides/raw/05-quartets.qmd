---
title: "Causal inference is not just a statistics problem"
author: "Lucy D'Agostino McGowan"
institute: "Wake Forest University"
format: kakashi-revealjs
knitr:
  opts_chunk: 
    eval: false
fig-cap-location: bottom
---

```{r}
#| include: false
#| eval: true
options(
  tibble.max_extra_cols = 7, 
  tibble.width = 60
)
library(quartets)
library(tidyverse)
library(ggdag)
library(gt)
```

# Causal Inference is not a statistics problem {background-color="#23373B"}

# Causal Inference is not *just* a statistics problem {background-color="#23373B"}

## *The problem*

:::{.large}
We have measured variables, what should we adjust for?
:::

. . .

**exposure** | **outcome** | **covariate**
---|---|---
0.49 | 1.71 | 2.24
0.07 | 0.68 | 0.92
0.40 | -1.60 | -0.10
. | . | .
. | . | .
. | . | .
0.55 | -1.73 | -2.34

## *What does the data say?*

:::: columns

::: column
```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
ggplot(causal_confounding, aes(x = exposure, y = outcome)) + 
  geom_point() + 
  geom_smooth(method = "lm", formula = "y ~ x")
```

**One unit increase in the exposure yields an average increase in the outcome of 1**
:::

::: column

```{r}
#| echo: true
cor(exposure, covariate)
```

```{r}
#| echo: false
#| eval: true
cor(causal_confounding$exposure, causal_confounding$covariate) |>
  round(digits = 2)
```

**The exposure and measured factor are positively correlated**
:::

::::

##

:::: columns

::: column

![](img/shake.png)
:::

::: column

### To adjust or not adjust? That is the question.
:::
::::

## *Causal Quartet* 

```{r}
#| echo: false
#| eval: true
#| fig.width: 8.5
coords <- list(
  x = c(X = 2, Z = 1, Y = 3),
  y = c(X = 1, Z = 1.1, Y = 1)
)

d_conf <- dagify(
  X ~ Z,
  Y ~ X + Z,
  exposure = "X",
  outcome = "Y",
  labels = c(X = "X", Y = "Y", Z = "Z"),
  coords = coords
) |>
  tidy_dagitty() |> 
  as_tibble()

coords <- list(
  x = c(X = 1, Z = 3, Y = 2),
  y = c(X = 1, Z = 1.1, Y = 1)
) 

d_coll <- dagify(
  Z ~ X + Y,
  Y ~ X,
  exposure = "X",
  outcome = "Y",
  labels = c(X = "X", Y = "Y", Z = "Z"),
  coords = coords
) |>
  tidy_dagitty() |> 
  as_tibble()

coords <- list(
  x = c(X = 1, Z = 2, Y = 3),
  y = c(X = 1, Z = 1.1, Y = 1)
)

d_med <- dagify(
  Z ~ X,
  Y ~ Z,
  exposure = "X",
  outcome = "Y",
  labels = c(X = "X", Y = "Y", Z = "Z"),
  coords = coords
) |>
  tidy_dagitty() |> 
  as_tibble()

coords <- list(
  x = c(U1 = 1, U2 = 2, X = 3, Z = 3, Y = 5),
  y = c(U1 = 2, U2 = 4, X = 1, Z = 2, Y = 2)
)

d_mbias <- dagify(
  Z ~ U1 + U2,
  X ~ U1,
  Y ~ X + U2,
  exposure = "X",
  outcome = "Y",
  labels = c(X = "X", Y = "Y", Z = "Z"),
  coords = coords
) |>
  tidy_dagitty() |> 
  as_tibble()

dag_data <- bind_rows(
  `(1) Collider` = d_coll,
  `(2) Confounder` = d_conf,
  `(3) Mediator` = d_med,
  `(4) M-bias` = d_mbias,
  .id = "dag"
)

dags <- dag_data |>
  ggplot(
    aes(x = x, y = y, xend = xend, yend = yend)
  ) +
  geom_dag_point(aes(color = label)) +
  geom_dag_edges() +
  geom_dag_text() +
  theme_dag() +
  coord_cartesian(clip = "off") +
  scale_color_manual(values = c("#A8CF9E", "#51c1ad", "#357edd")) +
  theme(legend.position = "none") +
  facet_wrap(~dag, scales = "free") + 
  expand_plot(
    expand_x = expansion(c(0.25, 0.25)), 
    expand_y = expansion(c(0.25, 0.25))
  )

dags
```


## {.center .middle}

![](img/quartets-logo.png)

## *Your turn 1* {.small}

### Load the `quartets` package
###  For each of the following 4 datasets, create a scatterplot looking at the relationship between `exposure` and `outcome`: `causal_collider`, `causal_confounding`, `causal_mediator`, `causal_m_bias`
### For each of the above 4 datasets, look at the correlation between `exposure` and `covariate`
### *Stretch goal*: For each of the above 4 datasets, fit a linear model to examine the relationship between the `exposure` and the `outcome`

`r countdown::countdown(6)`

## *Relationship between exposure and outcome*

```{r}
#| echo: false
#| eval: true

ggplot(causal_quartet, aes(x = exposure, y = outcome)) + 
  geom_point() + 
  geom_smooth(method = "lm", formula = "y ~ x") + 
  facet_wrap(~ dataset)
```

## *Relationship between exposure and covariate*

```{r}
#| eval: true
causal_quartet |>
  group_by(dataset) |>
  summarise(corr = cor(exposure, covariate))
```

## *Observed effects* {.large}

```{r}
#| echo: false
#| eval: true
causal_quartet |>
  nest_by(dataset) |>
  mutate(
    ate_x = coef(lm(outcome ~ exposure, data = data))[2],
    ate_xz = coef(lm(outcome ~ exposure + covariate, data = data))[2],
    cor = cor(data$exposure, data$covariate)
  ) |>
  select(-data, dataset) |> 
  ungroup() |> 
  gt() |> 
  gt::cols_label(
    dataset = "Data generating mechanism",   
    ate_x = "ATE not adjusting for Z",       
    ate_xz = "ATE adjusting for Z", 
    cor = "Correlation of X and Z"
  ) |>
  fmt_number() |> 
  tab_options(table.font.size = "80%")
```

::: tiny
D'Agostino McGowan L, Gerke T, Barrett M (2023). 
Causal inference is not a statistical problem. Preprint arXiv:2304.02683v1.
:::

## The solution

```{r}
#| echo: false
#| eval: true
#| fig-width: 8.5
dags
```

## *Correct effects*

```{r}
#| echo: false
#| eval: true
tribble(
  ~"Data generating mechanism",	~"Correct causal model",	~"Correct causal effect",
  "(1) Collider",	"Y ~ X",	"1.0",
  "(2) Confounder",	"Y ~ X ; Z",	"0.5",
  "(3) Mediator",
  "Direct effect: Y ~ X ; Z
  Total Effect: Y ~ X",
  "Direct effect: 0.0
  Total effect: 1.0",
  "(4) M-Bias",	"Y ~ X",	"1.0"
) |> 
  gt() |> 
  tab_options(table.font.size = "100%")
```

::: tiny
D'Agostino McGowan L, Gerke T, Barrett M (2023). 
Causal inference is not a statistical problem. Preprint arXiv:2304.02683v1.
:::

## The *partial* solution

::: small
```{r}
#| echo: true
#| eval: true
causal_collider_time
```

:::

. . .

*Time-varying data*

## Time-varying DAG

```{r}
#| echo: false
#| eval: true
coords <- list(
  x = c(
    X_0 = 1, X_1 = 2, Z_1 = 2, Y_1 = 1.9, 
    X_2 = 3, Y_2 = 2.9, Z_2 = 3,
    X_3 = 4, Y_3 = 3.9, Z_3 = 4
  ),
  y = c(
    X_0 = 1, Y_0 = 1.05,
    X_1 = 1, Z_1 = 1.1, Y_1 = 1.05,
    X_2 = 1, Z_2 = 1.1, Y_2 = 1.05,
    X_3 = 1, Z_3 = 1.1, Y_3 = 1.05
  )
)

d_coll <- dagify(
  Y_2 ~ X_1,
  Y_3 ~ X_2,
  X_2 ~ X_1,
  Z_2 ~ X_1 + Y_2,
  Z_3 ~ X_2 + Y_3 + Z_2,
  exposure = "X_2",
  outcome = "Y_3",
  labels = c(
    X_0 = "X",
    X_1 = "X",
    X_2 = "X",
    X_3 = "X",
    Y_0 = "Y",
    Y_1 = "Y",
    Y_2 = "Y",
    Y_3 = "Y",
    Z_1 = "Z",
    Z_2 = "Z",
    Z_3 = "Z"
  ),
  coords = coords
)

col_bias <- d_coll |>
  tidy_dagitty() |>
  mutate(color = case_when(
    !(name %in% c("X_2", "Y_3", "Z_3")) ~ "grey",
    TRUE ~ label)) |>
  ggplot(
    aes(x = x, y = y, xend = xend, yend = yend)
  ) +
  geom_dag_point(aes(color = color)) +
  geom_dag_edges() +
  geom_dag_text(aes(label = label)) +
  theme_dag() +
  coord_cartesian(clip = "off")  +
  scale_color_manual(values = c("lightgrey", "#A8CF9E", "#51c1ad", "#357edd")) +
  theme(legend.position = "none") + 
  geom_vline(xintercept = c(2.6, 3.25, 3.6, 4.25), lty = 2) + 
  annotate("label", x = 2.925, y = 0.97, label = "baseline") + 
  annotate("label", x = 3.925, y = 0.97, label = "follow-up")

no_col_bias <- d_coll |>
  tidy_dagitty() |>
  mutate(color = case_when(
    !(name %in% c("X_2", "Y_3", "Z_2")) ~ "grey",
    TRUE ~ label)) |>
  ggplot(
    aes(x = x, y = y, xend = xend, yend = yend)
  ) +
  geom_dag_point(aes(color = color)) +
  geom_dag_edges() +
  geom_dag_text(aes(label = label)) +
  theme_dag() +
  coord_cartesian(clip = "off")  +
  scale_color_manual(values = c("lightgrey", "#A8CF9E", "#51c1ad", "#357edd")) +
  theme(legend.position = "none") + 
  geom_vline(xintercept = c(2.6, 3.25, 3.6, 4.25), lty = 2) + 
  annotate("label", x = 2.925, y = 0.97, label = "baseline") + 
  annotate("label", x = 3.925, y = 0.97, label = "follow-up")
```

```{r}
#| echo: false
#| eval: true
col_bias
```

. . .

**True causal effect**: 1
**Estimated causal effect**: 0.55

## Time-varying DAG

```{r}
#| echo: false
#| eval: true
no_col_bias
```

. . .

**True causal effect**: 1
**Estimated causal effect**: 1

# `outcome_followup ~ exposure_baseline + covariate_baseline` {.tiny background-color="#23373B"}

## *Your turn 2*

### For each of the following 4 datasets, fit a linear linear model examining the relationship between `outcome_followup` and `exposure_baseline` adjusting for `covariate_baseline`: `causal_collider_time`, `causal_confounding_time`, `causal_mediator_time`, `causal_m_bias_time`

`r countdown::countdown(6)`

## The *partial* solution

```{r}
#| echo: false
#| eval: true
causal_quartet_time |>
  nest_by(dataset) |>
  mutate(
    ate_x = coef(lm(outcome_followup ~ exposure_baseline, data = data))[2],
    ate_xz = coef(lm(outcome_followup ~ exposure_baseline + covariate_baseline, 
                     data = data))[2]
  ) |>
  bind_cols(tibble(truth = c(1, 0.5, 1, 1))) |>
  select(-data, dataset) |> 
  ungroup() |> 
  gt() |> 
  gt::cols_label(
    dataset = "Data generating mechanism",   
    ate_x = "ATE not adjusting for pre-exposure Z",
    ate_xz = "ATE adjusting for pre-exposure Z", 
    truth = "Correct causal effect"
  ) |>
  fmt_number() |> 
  tab_options(table.font.size = "80%")
```


::: tiny
D'Agostino McGowan L, Gerke T, Barrett M (2023). 
Causal inference is not a statistical problem. Preprint arXiv:2304.02683v1.
:::

## *On M-Bias*

::: small
* The relationship between Z and the unmeasured confounders needs to be really large (Liu et al 2012)
* "To obsess about the possibility of [M-bias] generates bad practical advice in all but the most unusual circumstances" (Rubin 2009)
* There are (almost) no true zeros (Gelman 2011)
* Asymptotic theory shows that induction of M-bias is quite sensitive to various deviations from the exact M-Structure (Ding and Miratrix 2014)
:::


